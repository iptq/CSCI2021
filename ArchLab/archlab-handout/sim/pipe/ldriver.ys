#######################################################################
# Test for copying block of size 63;
#######################################################################
  .pos 0
main:  irmovq Stack, %rsp    # Set up stack pointer

  # Set up arguments for copy function and then invoke it
  irmovq $63, %rdx    # src and dst have 63 elements
  irmovq dest, %rsi  # dst array
  irmovq src, %rdi  # src array
  call ncopy     
  halt      # should halt with num nonzeros in %rax
StartFun:
#/* $begin ncopy-ys */
##################################################################
# ncopy.ys - Copy a src block of len words to dst.
# Return the number of positive words (>0) contained in src.
#
# Include your name and ID here.
# Michael Zhang <zhan4854@umn.edu>
#
# Firstly, I made use of iaddq, in order to prevent having to store
# constants into memory in order to add them. This reduces the number
# of instructions required for incrementing counters. This got my
# CPE down to about 12.7.
#
# I also used the loop unrolling technique to unroll the loop 5
# times. Because it was easy to use jle to compare to 0, I kept
# processing 5 elements at a time until I got to the last 4, at
# which point the counter would go negative. Then I would manually
# add back and execute the instructions 1-by-1 (since there are
# only at most 4 left).
#
##################################################################
# Do not modify this portion
# Function prologue.
# %rdi = src, %rsi = dst, %rdx = len
ncopy:

##################################################################
# You can modify this portion
  # Loop header
  xorq %rax,%rax    # count = 0;
  andq %rdx,%rdx    # len <= 0?
  jle Done    # if so, goto Done:
  iaddq $-5, %rdx # Check if it goes negative
  jl Last4

MainLoop:
  mrmovq (%rdi), %r8
  mrmovq 8(%rdi), %r9
  mrmovq 16(%rdi), %r10
  mrmovq 24(%rdi), %r11
  mrmovq 32(%rdi), %r12

  rmmovq %r8, (%rsi)
  rmmovq %r9, 8(%rsi)
  rmmovq %r10, 16(%rsi)
  rmmovq %r11, 24(%rsi)
  rmmovq %r12, 32(%rsi)

  andq %r8, %r8
  jle N2
  iaddq $1, %rax
N2:
  andq %r9, %r9
  jle N3
  iaddq $1, %rax
N3:
  andq %r10, %r10
  jle N4
  iaddq $1, %rax
N4:
  andq %r11, %r11
  jle N5
  iaddq $1, %rax
N5:
  andq %r12, %r12
  jle Final
  iaddq $1, %rax

Final:
  iaddq $40, %rdi
  iaddq $40, %rsi
  iaddq $-5, %rdx
  jge MainLoop

Last4:
  iaddq $4, %rdx # Restore from negative
  jl Done
  mrmovq (%rdi), %r8
  rmmovq %r8, (%rsi)
  andq %r8, %r8
  jle Last3
  iaddq $1, %rax
Last3:
  iaddq $-1, %rdx
  jl Done
  mrmovq 8(%rdi), %r8
  rmmovq %r8, 8(%rsi)
  andq %r8, %r8
  jle Last2
  iaddq $1, %rax
Last2:
  iaddq $-1, %rdx
  jl Done
  mrmovq 16(%rdi), %r8
  rmmovq %r8, 16(%rsi)
  andq %r8, %r8
  jle Last1
  iaddq $1, %rax
Last1:
  iaddq $-1, %rdx
  jl Done
  mrmovq 24(%rdi), %r8
  rmmovq %r8, 24(%rsi)
  andq %r8, %r8
  jle Done
  iaddq $1, %rax

##################################################################
# Do not modify the following section of code
# Function epilogue.
Done:
  ret
##################################################################
# Keep the following label at the end of your function
End:
#/* $end ncopy-ys */

EndFun:

###############################
# Source and destination blocks 
###############################
  .align 8
src:
	.quad -1
	.quad 2
	.quad 3
	.quad 4
	.quad 5
	.quad -6
	.quad 7
	.quad -8
	.quad 9
	.quad 10
	.quad 11
	.quad 12
	.quad -13
	.quad 14
	.quad -15
	.quad 16
	.quad -17
	.quad 18
	.quad 19
	.quad 20
	.quad -21
	.quad -22
	.quad -23
	.quad 24
	.quad -25
	.quad -26
	.quad 27
	.quad -28
	.quad -29
	.quad -30
	.quad 31
	.quad 32
	.quad 33
	.quad 34
	.quad -35
	.quad 36
	.quad -37
	.quad 38
	.quad -39
	.quad -40
	.quad -41
	.quad -42
	.quad -43
	.quad -44
	.quad -45
	.quad 46
	.quad -47
	.quad -48
	.quad -49
	.quad 50
	.quad -51
	.quad 52
	.quad -53
	.quad 54
	.quad -55
	.quad 56
	.quad -57
	.quad -58
	.quad -59
	.quad 60
	.quad 61
	.quad 62
	.quad 63
  .quad 0xbcdefa # This shouldn't get moved

  .align 16
Predest:
  .quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
  .quad 0xdefabc

.align 8
# Run time stack
  .quad 0
  .quad 0
  .quad 0
  .quad 0
  .quad 0
  .quad 0
  .quad 0
  .quad 0
  .quad 0
  .quad 0
  .quad 0
  .quad 0
  .quad 0
  .quad 0
  .quad 0
  .quad 0

Stack:
